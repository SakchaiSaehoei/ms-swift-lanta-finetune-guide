{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8811722f-d857-4667-beab-051b4177ef84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e3f70-9f98-41f9-94b9-cbf7d5e1acb3",
   "metadata": {},
   "source": [
    "# Data clenaing \n",
    "## expected data format for fintune on swift\n",
    "{\"system\": \"你是个优秀的论文分类师\", \n",
    " \"conversation\": [{\"human\": \"Based on the title 'Methods to integrate a language model with semantic information for a\\n  word prediction component', authors 'Tonio Wandmacher, Jean-Yves Antoine', and abstract 'Most current word prediction systems make use of n-gram language models (LM) to estimate the probability of the following word in a phrase. In the past years there have been many attempts to enrich such language models with further syntactic or semantic information. We want to explore the predictive powers of Latent Semantic Analysis (LSA), a method that has been shown to provide reliable information on long-distance semantic dependencies between words in a context. We present and evaluate here several methods that integrate LSA-based information with a standard language model: a semantic cache, partial reranking, and different forms of interpolation. We found that all methods show significant improvements, compared to the 4-gram baseline, and most of them to a simple cache model as well.', please determine the scientific category of this paper. Additional info: 10 pages ; EMNLP'2007 Conference (Prague) \\n\\nA. astro-ph\\nB. cond-mat.mes-hall\\nC. cond-mat.mtrl-sci\\nD. cs.CL\\nE. cs.CV\\nF. cs.LG\\nG. gr-qc\\nH. hep-ph\\nI. hep-th\\nJ. quant-ph\",\n",
    "                   \"assistant\": \"D\"}]}\n",
    "\n",
    "##  Current format \n",
    "{\"context\": \"patient : 慢性荨麻疹怎么根治？（女，20岁） \\ndoctor : 你好，慢性荨麻疹发生多长时间了？ \\ndoctor : 当地检查过过敏源吗？ \\npatient : 4个月 \\ndoctor : 检查过过敏源吗？ \\npatient : 还没有检查过敏源 \\npatient : 一直在吃药，依巴斯汀片 \\npatient : 不过只要一停药，隔几天又立刻出现红疙瘩 \\ndoctor : 荨麻疹的发生原因是过敏引起的 \\ndoctor : 中医的原因比较复杂，可能是饮食不节，伤了脾胃，也可能发生 \\npatient : 那请问有什么办法可以治疗吗？ \\ndoctor : 中医的风寒暑湿燥火，也可以引起 \\npatient : 那我具体要怎么做呢？才可以治愈 \\ndoctor : 中医方面平时气血不足，也可以引起的 \\ndoctor : 从西医方面论论它的发生原因，过敏源可能是吃的食物及添加剂 \\ndoctor : 感染因素，比如细菌，病毒感染，慢性胃炎，里头的幽门螺旋杆菌感染，或者是肝炎，肝炎，病毒感染，都可以引起慢性荨麻疹 \\ndoctor : 周围环境的物理化学因素也可以引起身体过敏 \\ndoctor : 慢性荨麻疹，建议你采用中西医结合的治疗方法 \\ndoctor : 第一，尽量到当地医院检查过敏的原因，并避免接触他 \\ndoctor : 建议上午口服氯雷他定片一片，下午口服左西替利嗪片一片。中成药可以口服肤痒颗粒 \\ndoctor : 第三请不要吃辛辣刺激性饮食，如辣椒，酒，不要吃鱼虾，牛羊肉容易引起过敏，不要搔抓。不要热水烫洗。 \\ndoctor : 或者到当地医院的找中医科医生当面辨证论治和汤药，全身调理 \\ndoctor : 同时，口服西药，依巴斯丁片，或者是氯雷他定片或者是左西替利嗪片都可以 \\npatient : 好的好的，谢谢医生 \\ndoctor : 不客气 \\n\", \"source\": \"周围环境的物理化学因素也可以引起身体过敏\", \"translation\": \"ปัจจัยทางกายภาพและเคมีในสภาพแวดล้อมโดยรอบ ก็สามารถทำให้เกิดอาการแพ้ในร่างกายได้เช่นกัน\"}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eeaefc7-152a-4f27-9244-d1955f4cd531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 18600/18600 [00:00<00:00, 55659.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = \"/project/lt200344-zhthmt/Y/MS-SWIFT/data/train.jsonl\"\n",
    "output_path = \"/project/lt200344-zhthmt/Y/MS-SWIFT/data/ready_to_train.jsonl\"\n",
    "\n",
    "# Step 1: Count total lines for tqdm progress bar\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# Step 2: Transform and save\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    for line in tqdm(infile, total=total_lines, desc=\"Processing\"):\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            source = data.get(\"source\", \"\").strip()\n",
    "            translation = data.get(\"translation\", \"\").strip()\n",
    "\n",
    "            # Build new JSONL line\n",
    "            new_line = {\n",
    "                \"system\": \"你是一个优秀的中泰医疗翻译师\",\n",
    "                \"conversation\": [\n",
    "                    {\"human\": source, \"assistant\": translation}\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            outfile.write(json.dumps(new_line, ensure_ascii=False) + \"\\n\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ Skipped malformed line.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f7fdc-59c1-4dc9-93df-6f7391a2bcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
